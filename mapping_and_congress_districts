import pandas as pd
import matplotlib
import numpy as np
import math
import geopandas as gpd
import random
from bs4 import BeautifulSoup
import html5lib
import requests
import regex as re

states = gpd.read_file('/Users/gmoos19/Downloads/tl_2021_us_state/tl_2021_us_state.shp')
districts = gpd.read_file('/Users/gmoos19/Downloads/tl_2021_us_cd116/tl_2021_us_cd116.shp')

districts['RANDOM'] = np.random.randint(1, 3, districts.shape[0])
districts.plot(column='RANDOM', cmap='magma', figsize=(200, 200))

regions = {'Index': ['1','2','3','4'], 'Region': ['Northeast','Midwest', 'South','West']}
r_df = pd.DataFrame(regions)

r = requests.get("https://www.nrcs.usda.gov/wps/portal/nrcs/detail/?cid=nrcs143_013696")
soup = BeautifulSoup(r.content)
soup.find_all('th')
names = []
postal_codes = []
FIPS = []
names.append(str(soup.find_all('th')[0]).replace('<th scope="col">',"").replace('</th>',"").replace('\r\n\t\t\t\t',""))
postal_codes.append(str(soup.find_all('th')[1]).replace('<th scope="col">',"").replace('</th>',"").replace('\r\n\t\t\t\t',""))
FIPS.append(str(soup.find_all('th')[2]).replace('<th scope="col">',"").replace('</th>',"").replace('\r\n\t\t\t\t',""))
fp_list = soup.find_all('td')
for i in range(30,195,3):
    names.append(str(fp_list[i]).replace("</td>","").replace('<td>\r\n\t\t\t\t',""))
    postal_codes.append(str(fp_list[i+1]).replace("</td>","").replace('<td>\r\n\t\t\t\t',""))
    FIPS.append(str(fp_list[i+2]).replace("</td>","").replace('<td>\r\n\t\t\t\t',""))
    
state_fps = {names[0]: names[1:], postal_codes[0]: postal_codes[1:], FIPS[0]: FIPS[1:]}
state_fps_df = pd.DataFrame(state_fps)

districts = districts.merge(state_fps_df,how='left', left_on='STATEFP', right_on='FIPS').drop(columns='FIPS')
region_state_df = states[['REGION','STUSPS']]
region_state_df = region_state_df.merge(r_df, how='left', left_on='REGION', right_on='Index').drop(columns=['Index','REGION'])
districts = districts.merge(region_state_df,how='left', left_on='Postal Code', right_on='STUSPS').drop(columns='STUSPS')

congressional = requests.get('https://www.house.gov/representatives')
soup1 = BeautifulSoup(congressional.content)
congress_people = soup1.find_all('table')
congress_people[0]
states=[]
for state_leg in congress_people:
    dists = []
    reps = []
    state_leg_dict = {}
    state_leg = str(state_leg)
    state = re.search('>\n(.*)\n                </caption>', state_leg)
    state_name = state.group(1).strip()
    districts = re.findall('class="views-field views-field-value-2"(.*)        </td>', state_leg)
    full_names = re.findall('.house.gov">(.*)</a> </td>', state_leg) + re.findall('.house.gov/">(.*)</a> </td>', state_leg)
    party = re.findall('class="views-field views-field-value-7"(.*)        </td>', state_leg)
    if len(state_name) > 1:
        state_leg_dict[state_name] = []
        for i in party:
            reps.append(i[-1])
        for dist in districts:
            dists.append(dist.split('>')[-1])
        state_leg_dict[state_name].append(reps)
        state_leg_dict[state_name].append(dists)
        state_leg_dict[state_name].append(full_names)
        states.append(state_leg_dict)
        
